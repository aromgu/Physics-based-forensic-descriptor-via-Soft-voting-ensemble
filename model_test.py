# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nYDE2EhNq6beNdAAfp6hArUgFBqo2_mg
"""

import os
import random
import warnings
warnings.filterwarnings(action='ignore')
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict, KFold
from sklearn.linear_model import LogisticRegression, RidgeClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score

np.random.seed(4321)
random.seed(4321)

data_rootpath = '/content/drive/MyDrive/splicing'
normal_path = os.path.join(data_rootpath, 'normal.csv')
splicing_path = os.path.join(data_rootpath, 'splicing.csv')

normal_df = pd.read_csv(normal_path)
splicing_df = pd.read_csv(splicing_path)

non_aug_df = pd.concat([normal_df, splicing_df], axis=0)

non_aug_df = non_aug_df.dropna()

non_aug_df=non_aug_df.sample(frac=1).reset_index(drop=True)

X, y = non_aug_df[['Dd', 'Hd', 'Td']], non_aug_df[['label']]

logistic_clf = LogisticRegression(random_state=4321)
score = cross_val_score(logistic_clf, X, y, cv=5)
print('accuracy mean : ', np.round(np.mean(score), 6))
print('accuracy std : ', np.round(np.std(score), 6))

param_grid = {
    'penalty' : ['l2'],
    'C' : [0.001, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100],
    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']
}

logistic_clf = LogisticRegression(random_state=4321)

grid_search = GridSearchCV(estimator=logistic_clf, 
                           param_grid=param_grid, 
                           cv=5,
                           verbose=1,
                           n_jobs=-1)

grid_search.fit(X, y)

print(grid_search.best_params_)
best_logistic_clf = grid_search.best_estimator_
print(best_logistic_clf)

score = cross_val_score(best_logistic_clf, X, y, cv=5)
print('accuracy mean : ', np.round(np.mean(score), 6))
print('accuracy std : ', np.round(np.std(score), 6))

param_grid = {
    'criterion': ['gini', 'entropy'],
    'splitter' : ['best', 'random'],
}

dt_clf = DecisionTreeClassifier(random_state=4321)
grid_search = GridSearchCV(estimator=dt_clf, 
                           param_grid=param_grid, 
                           cv=5,
                           verbose=2,
                           n_jobs=-1)

grid_search.fit(X, y)

print(grid_search.best_params_)
best_df_clf = grid_search.best_estimator_
print(best_df_clf)

score = cross_val_score(best_df_clf, X, y, cv=5)
print('accuracy mean : ', np.round(np.mean(score), 6))
print('accuracy std : ', np.round(np.std(score), 6))

param_grid = {
    'C': [0.001, 0.05, 0.1, 0.5, 1],
    'kernel' : ['rbf', 'linear'],
    'gamma' : [0.001, 0.01, 0.1, 1]
}

svm_clf = SVC(random_state=4321, probability=True)
grid_search = GridSearchCV(estimator=svm_clf, 
                           param_grid=param_grid, 
                           cv=5,
                           verbose=1,
                           n_jobs=-1)

grid_search.fit(X, y)

print(grid_search.best_params_)
best_svm_clf = grid_search.best_estimator_
print(best_svm_clf)

score = cross_val_score(best_svm_clf, X, y, cv=5)
print('accuracy mean : ', np.round(np.mean(score), 6))
print('accuracy std : ', np.round(np.std(score), 6))

gnb_clf = GaussianNB()
score = cross_val_score(gnb_clf, X, y, cv=5)
print('accuracy mean : ', np.round(np.mean(score), 6))
print('accuracy std : ', np.round(np.std(score), 6))

param_grid = {
    'max_depth': [None] + [i for i in range(1, 20 + 1)],
    'n_estimators' : [100, 300, 500, 1000],
    'criterion': ['gini', 'entropy']
}

rf_clf = RandomForestClassifier(random_state=4321)
grid_search = GridSearchCV(estimator=rf_clf, 
                           param_grid=param_grid, 
                           cv=5,
                           verbose=2,
                           n_jobs=-1)

grid_search.fit(X, y)

print(grid_search.best_params_)
best_rf_clf = grid_search.best_estimator_
print(best_rf_clf)

score = cross_val_score(best_rf_clf, X, y, cv=5)
print('accuracy mean : ', np.round(np.mean(score), 6))
print('accuracy std : ', np.round(np.std(score), 6))

param_grid = {
    'max_depth': [None] + [i for i in range(1, 20 + 1)],
    'n_estimators' : [100, 300, 500, 1000],
    'learning_rate' : [0.1, 0.01, 0.001, 0.0001],
    'loss' : ['deviance', 'exponential'],
    'min_samples_leaf' : [100, 150, 300],
    'max_features' : [1.0, 0.5, 0.3, 0.1]
}

gbc_clf = GradientBoostingClassifier(random_state=4321)
grid_search = GridSearchCV(estimator=gbc_clf, 
                           param_grid=param_grid, 
                           cv=5,
                           verbose=2,
                           n_jobs=-1)

grid_search.fit(X, y)

print(grid_search.best_params_)
best_gbc_clf = grid_search.best_estimator_
print(best_gbc_clf)

score = cross_val_score(best_gbc_clf, X, y, cv=5)
print('accuracy mean : ', np.round(np.mean(score), 6))
print('accuracy std : ', np.round(np.std(score), 6))

param_grid = {
    'hidden_layer_sizes': [i for i in range(1, 10)],
    'activation' : ['identity', 'relu', 'tanh', 'logistic'],
    'solver' : ['lbfgs', 'sgd', 'adam'],
    'alpha' : [0, 0.0001, 0.001, 0.01, 0.1, 1],
    'batch_size' : [1, 2, 4, 8, 16, 32, 64, 128],
    'learning_rate' : ['constant', 'invscaling', 'adaptive']
}

mlp_clf = MLPClassifier(random_state=4321)
grid_search = GridSearchCV(estimator=mlp_clf, 
                           param_grid=param_grid, 
                           cv=5,
                           verbose=2,
                           n_jobs=-1)

grid_search.fit(X, y)

print(grid_search.best_params_)
best_mlp_clf = grid_search.best_estimator_
print(best_mlp_clf)

score = cross_val_score(best_mlp_clf, X, y, cv=5)
print('accuracy mean : ', np.round(np.mean(score), 6))
print('accuracy std : ', np.round(np.std(score), 6))

param_grid = {
    'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 5, 10, 50, 100],
    'solver' : ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']
}

ridge_clf = RidgeClassifier(random_state=4321)
grid_search = GridSearchCV(estimator=ridge_clf, 
                           param_grid=param_grid, 
                           cv=5,
                           verbose=2,
                           n_jobs=-1)

grid_search.fit(X, y)

print(grid_search.best_params_)
best_ridge_clf = grid_search.best_estimator_
print(best_ridge_clf)

score = cross_val_score(best_mlp_clf, X, y, cv=5)
print('accuracy mean : ', np.round(np.mean(score), 6))
print('accuracy std : ', np.round(np.std(score), 6))

# !pip install lightgbm

from lightgbm import LGBMClassifier

param_grid = {
    'max_depth': [None] + [i for i in range(1, 20 + 1)],
    'learning_rate' : [0.1, 0.01, 0.001, 0.0001],
    'n_estimators' : [100, 300, 500, 1000],
}

light_clf = LGBMClassifier(random_state=4321)
grid_search = GridSearchCV(estimator=light_clf, 
                           param_grid=param_grid, 
                           cv=5,
                           verbose=2,
                           n_jobs=-1)

grid_search.fit(X, y)

print(grid_search.best_params_)
best_light_clf = grid_search.best_estimator_
print(best_light_clf)

score = cross_val_score(best_light_clf, X, y, cv=5)
print('accuracy mean : ', np.round(np.mean(score), 6))
print('accuracy std : ', np.round(np.std(score), 6))

# !pip install xgboost

from xgboost import XGBClassifier

param_grid = {
    'max_depth': [None] + [i for i in range(1, 20 + 1)],
    'learning_rate' : [0.1, 0.01, 0.001, 0.0001],
    'n_estimators' : [100, 300, 500, 1000],
}

xgb_clf = XGBClassifier(random_state=4321)
grid_search = GridSearchCV(estimator=xgb_clf, 
                           param_grid=param_grid, 
                           cv=5,
                           verbose=2,
                           n_jobs=-1)

grid_search.fit(X, y)

print(grid_search.best_params_)
best_xgb_clf = grid_search.best_estimator_
print(best_xgb_clf)

score = cross_val_score(best_xgb_clf, X, y, cv=5)
print('accuracy mean : ', np.round(np.mean(score), 6))
print('accuracy std : ', np.round(np.std(score), 6))

splits = KFold(n_splits=5, shuffle=False).split(X)

acc, precision, recall, f1, auc = [], [], [], [], []
for train_idx, test_idx in splits :
  voting_clf = VotingClassifier(
  [('logistic', best_logistic_clf), ('dt', best_df_clf), ('gaussian nb', gnb_clf), 
    ('svm', best_svm_clf), ('random forest', best_rf_clf), ('gbc', best_gbc_clf), 
    ('mlp', best_mlp_clf), ('lightgbm', best_light_clf), ('xgboost', best_xgb_clf)])
    
  X_fold_train, y_fold_train = X.iloc[train_idx], y.iloc[train_idx]
  X_fold_test, y_fold_test = X.iloc[test_idx], y.iloc[test_idx]

  voting_clf.fit(X_fold_train, y_fold_train)
  predict = voting_clf.predict(X_fold_test)
  
  acc.append(np.round(accuracy_score(y_fold_test, predict), 6))
  precision.append(np.round(precision_score(y_fold_test, predict), 6))
  recall.append(np.round(recall_score(y_fold_test, predict), 6))
  f1.append(np.round(f1_score(y_fold_test, predict), 6))
  auc.append(np.round(roc_auc_score(y_fold_test, predict), 6))

print('accuracy mean : ', np.round(np.mean(acc), 6))
print('accuracy std : ', np.round(np.std(acc), 6))

print('\nprecision mean : ', np.round(np.mean(precision), 6))
print('precision std : ', np.round(np.std(precision), 6))

print('\nrecall mean : ', np.round(np.mean(recall), 6))
print('recall std : ', np.round(np.std(recall), 6))

print('\nf1 score mean : ', np.round(np.mean(f1), 6))
print('f1 score std : ', np.round(np.std(f1), 6))

print('\nauc mean : ', np.round(np.mean(auc), 6))
print('auc std : ', np.round(np.std(auc), 6))

splits = KFold(n_splits=5, shuffle=False).split(X)

acc, precision, recall, f1, auc = [], [], [], [], []
for train_idx, test_idx in splits :
  X_fold_train, y_fold_train = X.iloc[train_idx], y.iloc[train_idx]
  X_fold_test, y_fold_test = X.iloc[test_idx], y.iloc[test_idx]

  best_logistic_clf.fit(X_fold_train, y_fold_train)
  predict = best_logistic_clf.predict(X_fold_test)
  
  acc.append(np.round(accuracy_score(y_fold_test, predict), 6))
  precision.append(np.round(precision_score(y_fold_test, predict), 6))
  recall.append(np.round(recall_score(y_fold_test, predict), 6))
  f1.append(np.round(f1_score(y_fold_test, predict), 6))
  auc.append(np.round(roc_auc_score(y_fold_test, predict), 6))

print('accuracy mean : ', np.round(np.mean(acc), 6))
print('accuracy std : ', np.round(np.std(acc), 6))

print('\nprecision mean : ', np.round(np.mean(precision), 6))
print('precision std : ', np.round(np.std(precision), 6))

print('\nrecall mean : ', np.round(np.mean(recall), 6))
print('recall std : ', np.round(np.std(recall), 6))

print('\nf1 score mean : ', np.round(np.mean(f1), 6))
print('f1 score std : ', np.round(np.std(f1), 6))

print('\nauc mean : ', np.round(np.mean(auc), 6))
print('auc std : ', np.round(np.std(auc), 6))

ensemble_predict = cross_val_predict(voting_clf, X, y)
lr_predict = cross_val_predict(best_logistic_clf, X, y)

from sklearn.metrics import roc_curve

ensemble_fpr, ensemble_tpr, threshold = roc_curve(y, ensemble_predict)
lr_fpr, lr_tpr, threshold = roc_curve(y, lr_predict)

plt.plot(ensemble_fpr, ensemble_tpr)
plt.plot(lr_fpr, lr_tpr)
plt.plot([0, 1], [0, 1], 'r--')

ensemble_predict

lr_predict

np.array(y.values.reshape(-1))

